{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9c029b136d27496e86153e8198ab52b9",
      "a3adfb6879a24986984301bb79e17fee",
      "63a82c17be024cc890859275c9d6f203",
      "72072c2b96414f45ae63bbdf60c01df9",
      "1fcae32c14bd4c8a9bd333c39d684cb2",
      "2aad3753d53b4aed8f5e941de49b96fc",
      "2cc6d029045c49b3950496c262f27cf2",
      "2c6b880f68174ac1bd9449dd3aec1d9f",
      "7929cfa72fb64870afc2c8ac19aea6f0",
      "3544261a004843a5b307013f5eefb6e2",
      "a8055ab05faa4568938c3d4550067c5d",
      "1dd45e5730dd40b28b1cf39df39c7d64",
      "19b5e7034e824d22b14a9cc003d2eba7",
      "e563db3ed1ba48bc9bce8f1300b1bf11",
      "6810e79b6f964db690268fae528012aa",
      "570e17f031fb47c2b2329c6fa045e406",
      "39b452eb3732499b804f37a089294d93",
      "ac00182ee523434e94ec3315bd9a9546",
      "4191fa997af44544845f4ec96abb6bb3",
      "a1af95ab0c2944538d560d3fa2387d85",
      "5fbe92eec2764e75ab067c3696e8a7ad",
      "b658ae0fa8134f51b59bcdeb5ee089bd",
      "96f3f5d1d0ba4d1cb8b780999dbe021c",
      "336b45a1e7d54c66afb8899938809a48",
      "6958b0d05d5c4416bafe726e761b8527",
      "ff9d34416a1641e7900e37de5155be09",
      "785b17d74dd143eaaa59ea75202993fc",
      "764607ed25974def937b926aebbc0334",
      "68f24061a937457482872c74185478df",
      "29b46d9e4525445c8a3747309aa440d9",
      "3338b04430cc4f5797f2347feb568a4e",
      "136a8d64155e4e57ae1bc8d887e9ec66",
      "1bbecb26a2f045d2b277ce0417617042",
      "53822fab1a454c47a8bb3c9c40e1d90a",
      "ced6b0f0a48d424e893eba862b75d307",
      "758036f980d649b08a44a8d7cfd5d5aa",
      "ad3a4ef3b8b54952bd48d70b258b4d1a",
      "dd845afa530a4c779a94a0144c4a33dc",
      "5c34d029d6614abc86a3fba427a2aa5f",
      "90e8a26739514bd8a696a13c2ace15e7",
      "c32c1a900f5f4aa198b73e1df5c1d392",
      "72e2f9438ef948a79db2187f050be9af",
      "05904f7ab08443c9b399c53f7da4b699",
      "bad5919c55b9420eb9933f3bdd657eec",
      "e6b065c920e34a26b7aeaa57e68b3fd3",
      "2b4167377d1b4c379f6d5b55835cbd45",
      "5906762aace34e2389f927fc4191dcdd",
      "757168f797a34662aa0e7edab4383c71",
      "6a585191110b41d4b37fa5eaca280236",
      "6e8098d462f1460dbc59d0d2dd11a691",
      "fbe8c7a7d55e479a9408fbc183ad2dcd",
      "e834c93c58504b0eb25717d00fea7c8c",
      "29e724c881d34c998077e14100d198e8",
      "25771edc32c04a14a739b04fa15eeb34",
      "d87e9c07fc4e4711bf1597ccf3cbde32",
      "a487f1c7dbd7498698122615e9722820",
      "01da1bcdf87444cb9dd8ff5f45b3d0e2",
      "5fd57c1327f449139857cf374558ae86",
      "c21c389e97d34d3fb995d779b4ded4f2",
      "ea6b6bfb42394d379d47f86f2e3684cb",
      "4cd2e53161ee4fbdacf69b6f8c4afb1f",
      "4e465aac5b2943a5aa348269e25992c3",
      "5589647e884b47aab3d2b47b9e722aa7",
      "4d5a36a97149466e9956edaa4349c680",
      "5c45d85f46184fc09c4f804d79a41d20",
      "9c1e813cbc44468f9058c2ff61003e53",
      "11e0da19afb24b3badbfb6b947e6dc40",
      "df8c7562ef8b4eae9571c5615b5d7beb",
      "c3eae4bf2d0249949d11fe764dc3eaa9",
      "68b2866e36af465284d917d073fcdbc5",
      "ae55baeb18ba48ac935fe6a5cf6181ae",
      "e0d110e8964b4d41a63db72e5da36398",
      "59786252bc51493a86e320959bc257f0",
      "cf1da67fd8ba401a9ac02ef725f88367",
      "6b7e17914f324adb91fe6238ce456170",
      "74161bd9a2aa42d39af2a58e5f8f52ea",
      "9757b13f94bf4943a8911ff2558495c6",
      "fffa457fc2f646f68544c82bee92cb5d",
      "c5a6b0d599d44a96ad99eb1d67cd4395",
      "d812001fd5c04b35930cf76554cd92ef",
      "37998a62e4174c4aad309262835e0577",
      "ccb45220fec346e2859ddbaaec01123d",
      "dda985bdc774401eb5593c0c9d080c74",
      "d38d667d96d54512bb3f59c4b1ddd8a5",
      "cdbb8787bcdb40a28b068350b889eeed",
      "bed5c3dcaead43a091c0cd1ba7032287",
      "2077b10657ff43f798194b1066bf5601",
      "7d6be148bc0a43c7acff3462dd67a0d1",
      "29d6961684dd47e6b7d71512e2288231",
      "c5f2d94b9c8a46de87e1c63873424bd2",
      "3350ab12c475408c874c965f4ccbbc7b",
      "fad3c89e9feb4cc898e9e4e7191566aa",
      "49821c22a6be47a09a38e7d78daf3fff",
      "3306358e2d654affb8cdc51de9300d0c",
      "6fb83084e1de4026b5721cc8bb017247",
      "b60151b1e9c64814b2e60e4c099dddd9",
      "0f90812a516044af843bbae8e253b14a",
      "bee59fad85be4264b1e728e04b087236",
      "98a20d698df54b01988a7a5a40695af2",
      "01752b2d72744ee0b66d01f36c8f2523",
      "051da0dcdafe46429c96e618ecb7d0ac",
      "a7c142da4fe64b1bb4bce0551f82e9d3",
      "780faee258f84cb59c3a433ce225b448",
      "d22bbb9a072f4ab1959bef22a3f136a3",
      "0982b10ab3d94303afb9a2958e9628b3",
      "fa6944c0059d487e9dc0c8bb2d8a7081",
      "c395eac4a2b647ec966dd09f65dd95c4",
      "aead293cc3c04f6fb677c7afe405fa72",
      "5b7b27562da74619aeb5e18d7b1677e3",
      "7e113a66caa84f3fa136dd3454470622",
      "24053e655090400ba5c8b97a44c2c451",
      "ac32c73ab75c4ecd8a200c168292eea8",
      "8859661ba9374dc1a406d41a31faa913",
      "b5324c2b0753466f90e514e227dbaa90",
      "f05d3d8ce22b46b5b76cae6d16cb0877",
      "d727aca6016f49d78b5ec156d7bb9a0e",
      "a4e00a92cd454f3db5bfe993e27d1468",
      "70086f4d917d4931a38fb7fb489d8baa",
      "b41249d2ba3d4665bf4dada447363b7d",
      "a92b24e7c36a488d8f3319250e4d2e01",
      "f7755fc6e3774f21b818504aa3ab1b95",
      "f0f0b36042414978aa3c130862c54dac",
      "eda07bf707cd4b77b2108e3bbb844727",
      "b4bebb72f11b4449b6944c713066b5b0",
      "706b6e2eb8c44b1ba5b101b71ba76d88",
      "68eed525e2d14d9290f66bea44cff17f",
      "53c839ad812744c9a8c83bf31e9a17ee",
      "779a558783a143e194176ebeb1effc6e",
      "577441b923084055af4274b5e3dd7fa6",
      "dfe871800bb44d74add9407da916cc4e",
      "1b36498819234845a5032a15f3b302c6",
      "ad1765176d6c41f8aaade66cb90d9691",
      "2974d65ba87c4c04b332d9da8394433a",
      "8b76de6e2b9043638cadd8702525ee49",
      "2d59ea0d920041a783f7e369b3f1214b",
      "087afc8c3e994dd2b0390e3e0318b76e",
      "cd5c9e05d4a1470c9f4cd70194d2832a",
      "2e1c2b2b897b4e2e8c96dce9f4714948",
      "daaa7e3a12c044d9b961ca8d0c2cf4c0",
      "aa0179bb96754862ae15f8d97c52446d",
      "1b5173c40ec54392b56224902cd6b288",
      "2769d5cfd510439cb1a7bba49913f6a0",
      "50e5bc80b6294bbe9515b6e7c0c8b542",
      "d19d948d10554e9f90f2145193497809",
      "62748f3990f4467fae71f59c5e5c8ddc",
      "906a873878e14320bad3190c58b7bed3",
      "bbe0e45f677141c098d4337592af856c",
      "7aca14cc3bc447f385577d2db4176b93",
      "8e87a21880be4fd0b79c89c9d51c6af3",
      "dd4de713bdac4be183b8234c9a5139c9",
      "3c1384202b4047e98426da697a4d6ee7",
      "dca3739bc35b4f21aeeedcda4d0fc9ce",
      "bc5bb95b952a46998f8d49d24cf8cd7d",
      "b3421c90a49c43c09bc771d05e57ce57",
      "18431047106045f1b887cc0943443a7e",
      "5fb90c141dad467e898934bf96496b19",
      "6c7b3796d77044759edbfc1ef31eb237",
      "6bbadbea4f7748dfbde1bfd987e57355",
      "14373d3927c74907b8d660739d2a42eb",
      "ed87b72a141542dba2f4d80ea8614c47",
      "e5644c2461c64cc8b867c08191cf246b",
      "006ea1f963144b7abfc3518abc988a6c",
      "2e287f76df1b42418981b742b388a49a",
      "6d96370a6c4c4f368197ae81d1e1aebb",
      "45ebe8e85e3a4ac28db322d552c149ae",
      "559950b5afe941848a66cf0333464af4",
      "88e57f9127de430d9791a31e76efb791",
      "feb7b4d563714cc48f81b6421a42f973",
      "af1746ca55874dd5a34ab00eabd2a517",
      "1e4c2df617cf41948d957fd50e1b4505",
      "73b695f3ba5848af96f93fac717c0ce4",
      "ec46217a63db4887ae6c3af0d419b33a",
      "56acac9975464d53b911b9953959f272",
      "586799f83dd7441d97104adc34abf84b",
      "0ea718fc10bf4bf6b5db97f7bc124957",
      "9437619369304d5d9652d3be988d9766",
      "8b2505f0a779405bb9107d17c0ed9f62",
      "d007e02f5cab45a99146b8b306534fb2",
      "737b3c54456448b196fb05cccccfdbe6",
      "ed0f50ae79e24c7c92d23e060a4c4843",
      "01837eb8381f4480a5b11294806f23f6",
      "0d9f1926be804214bca68dcf2289d284",
      "4b9b9ef3516a46b49fd2954029d275df",
      "ca041568c1b943d5b68ed4cee4cb26b9",
      "95939dc6959d4cbe8b416ca2954749a4",
      "55e4ae300521420d8a65229eee2c154f",
      "8e81f412f3084e68a1abcca7dfd2c702",
      "5c2359cbbd04432c92e81652a73aa330",
      "8c1429ef38854ccfa17b8051579e79a3",
      "1715aa825137409ab6001e4455a6457d",
      "172834ece4d14c6f983de4567ac6c756",
      "974d56cb65e14e88a26eb2b256853bf0",
      "60b3897c436f4205ab7c7f23bf33a5f3",
      "ccda6df4b5f7484ba878245e1e4de9d0",
      "e3711ce6f73d46188e4635686dc8b385",
      "c4099fb0be8645ad9c604b5599864646",
      "1584ee9d6f31452cb92a092af4f98537",
      "f58b3b26165c46ab87358364d19fbe0f",
      "6f0ef48494e1423097977f2c9cace72d",
      "48fec6575f6f4ea5b2865173513da098",
      "2b614ccf50cb45b08a4a5497153605dd",
      "288a202798c048f4ad69d948e3a5ac4e",
      "ec737e661fb84fab83582b3b4f265852",
      "c0ac0a82eec04605aa0c6b99275deed3",
      "1b4fa970e76f4af29a90e78539f35c5f",
      "984c38ce1ee84cd994fe14aecff81a20",
      "0eb082b46f7f42a1b553fa2e4784e9f2",
      "3697d9e25bed42c6805bd7465a9b95c7",
      "dfe5d0348d1844dd9294e4651e5b8622",
      "61e4926479a24ac49d7a07868fb034a4",
      "58fa041ae66c4b179071779358c0f09f",
      "860315fd45724bfca3eca8712fb6313c",
      "b1184d58389c45fabba928538dd7cbf1",
      "96a00bad92564c7ca9489166144af343",
      "c503dfb4d77745b4a6b839b647cf2cb0",
      "be0b9a38f2cf4359b9cd995300d1099a",
      "acb0093376f7475d93930cba33b25f83",
      "1a335cd8a08c4899bcd6ac741eaa7098",
      "aa049601a6c84104bfa2ac514d2c06cc",
      "91b7a9c590104165b7bddacd43d12296",
      "acb7fdc308c948589c1d041da5ecd516",
      "8051bac4200042bbbca55c34d52c5fae",
      "903454088c4b4c71bf235f6d3b7fca16",
      "4710b880418b4b41948b2bfb60711d11",
      "f502b4219c974e1da972374a984771a2",
      "76406040f9ff42cea357fb16605aa971",
      "9e8993e740c345278ef19a2d8f823bc1",
      "2eef5c32b9ec4ced9e777f65a7cd7285",
      "eb81b732b926432c9b767e7bbddf3802",
      "d796a7a752d940478a0e634f7f0ffa28",
      "3ebfd35cea0942beaf6783044b49bb33",
      "90afbf3d4c9e48c1a1887a0d3f720d0c",
      "248225128ab54cb482ddcfe49de065fb",
      "6cabf48681ad4546b2c2c0ad19bd145c",
      "80b7587d9f7d402ebae0f651d4c4dbe6",
      "fdff9fa9eb2045d5a78a011591d0044f",
      "17a556ebf7de4bf8839d6702585c488b",
      "43538e357c7f42828436dcf8ac692e7d",
      "83b468c587c14836b7786895a0985d87",
      "9a39d356f84f4876b130200df654e61d",
      "7daaec24e9484d4ba54d82b162804228",
      "42f8d9849bf64dcbaa1341f3fbd3fc19",
      "6b7565427ddb4eb7a9502e5e5e8a7665",
      "e5abb772acba4779af05c74cfcb16c4a",
      "71bab53ce79d4942bc9c2f4f3703438c",
      "72ff5dabd0f441a6b853a36289357a43",
      "4212e48946c24b918ca082faa8ba4a37",
      "88e9a515bb704fccb704fe3ddc1cce18",
      "f81db3f41e424bf88d1c0d2266419ea8",
      "5b0ed8f6ff1f4b809b3f0f034709a2a5",
      "9e768e4c2e0644ad8b62f2b230ef18aa",
      "ea8cf2da177b4cccbe4980e5b9fab397",
      "7aaa2fc8b5c14d2e877fae7717da092f",
      "5c972c704d6047ce8b51bb9216fce4f8",
      "5d090816eba24f0c9ccdb54121a1deba",
      "529758732e80482e8d95633def6cb21d",
      "52e9cf48451d4e59b32824a21ded538c",
      "da09e089b0b043299f3549d4b003f688",
      "7029eeeaf0124477bc507c719e077245",
      "e5c46cd7f4884ad7be4c250b8eee5c8f",
      "7592c3c6654b47a8b972acf16225c63a",
      "ac8d7dea76e24b8fbb63dee6ff21b7c1",
      "97f109786bbc48cc86ead7d624977ca1",
      "c5512255ed33464b9c626c834802f2ac",
      "2ac37cac53ca4312b571d2b908e33a55",
      "6c77be874601475bbaacb9817191edb8",
      "78c399a6b52a41dda55ed660e86dd889",
      "8a10151aa40a46d8b0fee6524c2313dd",
      "040447521edd487f9bf4c2c0538fbe77",
      "496980cc84944a1ba97c7659afb43feb",
      "dc98d46a14904d339f84b80928b3b6cb",
      "a67da2d296b04288b4d42dbd9dcb72ef",
      "4e78c580e76245baa09d233a2fcc03d5",
      "cb76c4e6be514b4888a312aa2452546d",
      "27a9a897fd554e3b8627616eab290177",
      "f89220411a614bc399563a0d7a103492",
      "8ab83489e68449bb93895f6fdcf7e9e2",
      "0f6208fa19ac4b4c8199200b36737556",
      "dd118c79088e47c280e07477ae60a5d3",
      "933a77c44b5c4e64a49e17a80b9bde42",
      "abec1ff72b734b938a91cb7022f45bd3",
      "3080d1d3788a4cd9a6bac09d3071d0b5",
      "1d2f4bb3276b4654863dd37a0a08ddd8",
      "a078909fb9d4497aaf43383916e04de9",
      "fef5e19e68d84a9dafbfe620a4c3daf0",
      "b4b32f2d030c4671b3bb58c7f99ba421"
     ]
    },
    "id": "HrJLNAtuAde4",
    "outputId": "9de8d782-ca9e-4913-81fb-3bdd6b75ea6e"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Environmental Claims Classifier\n",
    "-------------------------------\n",
    "Tiny-BERT architecture with:\n",
    "- Lightweight text preprocessing\n",
    "- Class imbalance handling\n",
    "- Comprehensive metrics tracking\n",
    "- Hyperparameter optimization\n",
    "\n",
    "Runtime: ≈ 15 min on CPU-only, faster with GPU\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"Install required packages.\"\"\"\n",
    "    # CPU-only PyTorch installation\n",
    "    torch_install = \"pip install -qU torch==2.6.0+cpu torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\"\n",
    "    # Other dependencies\n",
    "    deps_install = \"pip install -qU transformers datasets pytorch-lightning torchmetrics matplotlib pandas scikit-learn\"\n",
    "\n",
    "    print(\"Installing dependencies...\")\n",
    "    os.system(torch_install)\n",
    "    os.system(deps_install)\n",
    "\n",
    "# Install dependencies\n",
    "install_dependencies()\n",
    "\n",
    "import re\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import datasets\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for model training and evaluation.\"\"\"\n",
    "\n",
    "    # Core settings\n",
    "    SEED: int = 42\n",
    "    BATCH_SIZE: int = 64\n",
    "    MAX_EPOCHS: int = 6\n",
    "    MAX_SEQ_LEN: int = 512\n",
    "    MODEL_NAME: str = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "    # Dataset\n",
    "    DATASET_NAME: str = \"climatebert/environmental_claims\"\n",
    "\n",
    "    # Model hyperparameter grids for optimization\n",
    "    HYPERPARAMETER_CONFIGS = [\n",
    "        {\"lr\": 3e-5, \"freeze_layers\": 0, \"weight_decay\": 0.01},\n",
    "        {\"lr\": 5e-5, \"freeze_layers\": 2, \"weight_decay\": 0.00},\n",
    "        {\"lr\": 2e-5, \"freeze_layers\": 0, \"weight_decay\": 0.01},\n",
    "        {\"lr\": 3e-5, \"freeze_layers\": 4, \"weight_decay\": 0.00},\n",
    "    ]\n",
    "\n",
    "    # Early stopping\n",
    "    EARLY_STOP_PATIENCE: int = 2\n",
    "    EARLY_STOP_METRIC: str = \"val_f1\"\n",
    "    EARLY_STOP_MODE: str = \"max\"\n",
    "\n",
    "    # Training\n",
    "    WARMUP_RATIO: float = 0.1\n",
    "    LOG_EVERY_N_STEPS: int = 10\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Handles loading, preprocessing, and preparing the environmental claims dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "    def load_dataset(self) -> Tuple[datasets.Dataset, datasets.Dataset]:\n",
    "        \"\"\"Load and prepare the environmental claims dataset.\"\"\"\n",
    "        logger.info(f\"Loading dataset: {self.config.DATASET_NAME}\")\n",
    "        env_ds = datasets.load_dataset(self.config.DATASET_NAME)\n",
    "        return env_ds[\"train\"], env_ds[\"validation\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean text with basic preprocessing.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+\", \" \", text)                   # strip URLs\n",
    "        text = re.sub(r\"[^a-z0-9\\s\\.,!?']\", \" \", text)         # basic ascii filter\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()               # normalize whitespace\n",
    "        return text\n",
    "\n",
    "    def clean_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Apply text cleaning to a batch.\"\"\"\n",
    "        return {\"text\": self.clean_text(batch[\"text\"])}\n",
    "\n",
    "    def tokenize_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Tokenize a batch of texts.\"\"\"\n",
    "        return self.tokenizer(\n",
    "            batch[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.config.MAX_SEQ_LEN\n",
    "        )\n",
    "\n",
    "    def prepare_datasets(self) -> Tuple[datasets.Dataset, datasets.Dataset]:\n",
    "        \"\"\"Prepare datasets for training and validation.\"\"\"\n",
    "        # Load raw datasets\n",
    "        train_ds, val_ds = self.load_dataset()\n",
    "\n",
    "        # Apply cleaning\n",
    "        logger.info(\"Cleaning text data\")\n",
    "        train_ds = train_ds.map(self.clean_batch)\n",
    "        val_ds = val_ds.map(self.clean_batch)\n",
    "\n",
    "        # Tokenize\n",
    "        logger.info(\"Tokenizing datasets\")\n",
    "        train_ds = train_ds.map(self.tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
    "        val_ds = val_ds.map(self.tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "        # Set format to PyTorch tensors\n",
    "        train_ds.set_format(\"torch\")\n",
    "        val_ds.set_format(\"torch\")\n",
    "\n",
    "        return train_ds, val_ds\n",
    "\n",
    "    def create_dataloaders(self, train_ds: datasets.Dataset, val_ds: datasets.Dataset) -> Tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"Create data loaders for training and validation.\"\"\"\n",
    "        train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        return train_loader, val_loader\n",
    "\n",
    "    def calculate_class_weights(self, train_ds: datasets.Dataset) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights to handle class imbalance.\"\"\"\n",
    "        cls_counts = np.bincount(train_ds[\"label\"])\n",
    "        # Inverse frequency weighting (normalized)\n",
    "        weights = torch.tensor(\n",
    "            cls_counts.sum() / (len(cls_counts) * cls_counts),\n",
    "            dtype=torch.float\n",
    "        )\n",
    "        return weights\n",
    "\n",
    "\n",
    "class EnvironmentalClaimClassifier(pl.LightningModule):\n",
    "    \"\"\"PyTorch Lightning module for environmental claim classification.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        num_classes: int = 2,\n",
    "        lr: float = 3e-5,\n",
    "        freeze_layers: int = 0,\n",
    "        weight_decay: float = 0.01,\n",
    "        class_weights: Optional[torch.Tensor] = None\n",
    "    ):\n",
    "        \"\"\"Initialize the classifier.\n",
    "\n",
    "        Args:\n",
    "            model_name: Name of the pretrained model\n",
    "            num_classes: Number of classes for classification\n",
    "            lr: Learning rate\n",
    "            freeze_layers: Number of encoder layers to freeze\n",
    "            weight_decay: L2 regularization weight\n",
    "            class_weights: Class weights for imbalanced dataset\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Load pre-trained model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_classes\n",
    "        )\n",
    "\n",
    "        # Freeze specified encoder layers if requested\n",
    "        if freeze_layers > 0:\n",
    "            logger.info(f\"Freezing {freeze_layers} encoder layers\")\n",
    "            for param in self.model.bert.encoder.layer[:freeze_layers].parameters():\n",
    "                param.requires_grad_(False)\n",
    "\n",
    "        # Set up loss function and metrics\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.acc = MulticlassAccuracy(num_classes=num_classes, average=\"macro\")\n",
    "        self.f1 = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n",
    "\n",
    "    def forward(self, **x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        return self.model(**x).logits\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        \"\"\"Common operations for both training and validation steps.\"\"\"\n",
    "        labels = batch.pop(\"label\")\n",
    "        logits = self(**batch)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        return loss, preds, labels\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        \"\"\"Training step.\"\"\"\n",
    "        loss, _, _ = self._shared_step(batch)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        \"\"\"Validation step.\"\"\"\n",
    "        loss, preds, labels = self._shared_step(batch)\n",
    "\n",
    "        # Update metrics\n",
    "        self.acc.update(preds, labels)\n",
    "        self.f1.update(preds, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=False,\n",
    "                 batch_size=labels.size(0))\n",
    "        self.log(\"val_acc\", self.acc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_f1\", self.f1, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer and learning rate scheduler.\"\"\"\n",
    "        # Set up optimizer\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "\n",
    "        # Set up learning rate scheduler with warmup\n",
    "        total_steps = self.trainer.estimated_stepping_batches\n",
    "        warmup_steps = int(Config.WARMUP_RATIO * total_steps)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}\n",
    "        }\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"Handles model evaluation and result visualization.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate_model(model, val_loader):\n",
    "        \"\"\"Evaluate model on validation set.\"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.eval().to(device)\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                labels = batch.pop(\"label\").to(device)\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                logits = model(**batch)\n",
    "                preds = logits.argmax(1)\n",
    "                y_true.extend(labels.cpu())\n",
    "                y_pred.extend(preds.cpu())\n",
    "\n",
    "        # Calculate metrics\n",
    "        report = classification_report(y_true, y_pred, digits=3, zero_division=0)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "        # Extract accuracy and F1 scores\n",
    "        acc = float(re.search(r\"accuracy\\s+([0-9.]+)\", report).group(1))\n",
    "        f1 = float(re.search(r\"macro avg\\s+[0-9.\\s]+\\s([0-9.]+)\\s+[0-9.]+\", report).group(1))\n",
    "\n",
    "        return {\"report\": report, \"cm\": cm, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_results(results_df, best_cm):\n",
    "        \"\"\"Plot evaluation results.\"\"\"\n",
    "        # Plot metrics by run\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        x = np.arange(len(results_df))\n",
    "        width = 0.35\n",
    "\n",
    "        ax.bar(x - width/2, results_df[\"acc\"], width, label=\"Accuracy\")\n",
    "        ax.bar(x + width/2, results_df[\"f1\"], width, label=\"F1-Score\")\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f\"Run {i}\" for i in x])\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlabel(\"Experiment Run\")\n",
    "        ax.set_ylabel(\"Score\")\n",
    "        ax.legend()\n",
    "        ax.set_title(\"Validation Metrics by Run\")\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot confusion matrix for best run\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        im = ax.imshow(best_cm, cmap='Blues')\n",
    "\n",
    "        # Add labels\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_yticks([0, 1])\n",
    "        ax.set_xticklabels([\"No Claim\", \"Claim\"])\n",
    "        ax.set_yticklabels([\"No Claim\", \"Claim\"])\n",
    "        ax.set_xlabel(\"Predicted Label\")\n",
    "        ax.set_ylabel(\"True Label\")\n",
    "        ax.set_title(\"Best Model Confusion Matrix\")\n",
    "\n",
    "        # Add text annotations\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                text_color = \"white\" if best_cm[i, j] > best_cm.max() / 2 else \"black\"\n",
    "                ax.text(j, i, best_cm[i, j], ha=\"center\", va=\"center\", color=text_color)\n",
    "\n",
    "        plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def train_and_evaluate(config: Config):\n",
    "    \"\"\"Main function to train and evaluate models.\"\"\"\n",
    "    # Set seeds for reproducibility\n",
    "    pl.seed_everything(config.SEED, workers=True)\n",
    "\n",
    "    # Set up data processor\n",
    "    processor = DataProcessor(config)\n",
    "\n",
    "    # Prepare datasets\n",
    "    logger.info(\"Preparing datasets\")\n",
    "    train_ds, val_ds = processor.prepare_datasets()\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = processor.create_dataloaders(train_ds, val_ds)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = processor.calculate_class_weights(train_ds)\n",
    "    logger.info(f\"Class weights: {class_weights}\")\n",
    "\n",
    "    # Set up early stopping callback\n",
    "    early_stopping = pl.callbacks.EarlyStopping(\n",
    "        monitor=config.EARLY_STOP_METRIC,\n",
    "        mode=config.EARLY_STOP_MODE,\n",
    "        patience=config.EARLY_STOP_PATIENCE,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Set up trainer\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1,\n",
    "        max_epochs=config.MAX_EPOCHS,\n",
    "        deterministic=True,\n",
    "        log_every_n_steps=config.LOG_EVERY_N_STEPS,\n",
    "        callbacks=[early_stopping],\n",
    "        enable_checkpointing=False,\n",
    "    )\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    results = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for i, hp_config in enumerate(config.HYPERPARAMETER_CONFIGS):\n",
    "        logger.info(f\"\\n▶️  Run {i}: {hp_config}\")\n",
    "\n",
    "        # Initialize model with current hyperparameters\n",
    "        model = EnvironmentalClaimClassifier(\n",
    "            model_name=config.MODEL_NAME,\n",
    "            class_weights=class_weights,\n",
    "            **hp_config\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "        # Evaluate model\n",
    "        eval_results = Evaluator.evaluate_model(model, val_loader)\n",
    "\n",
    "        # Store results\n",
    "        results.append({**hp_config, \"acc\": eval_results[\"acc\"], \"f1\": eval_results[\"f1\"]})\n",
    "        confusion_matrices.append(eval_results[\"cm\"])\n",
    "\n",
    "        # Print classification report\n",
    "        print(eval_results[\"report\"])\n",
    "\n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Find best model\n",
    "    best_idx = results_df.f1.idxmax()\n",
    "    best_config = results[best_idx]\n",
    "    best_cm = confusion_matrices[best_idx]\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n=== Results Summary ===\")\n",
    "    print(results_df)\n",
    "    print(f\"\\nBest run: {best_config}\")\n",
    "\n",
    "    # Plot results\n",
    "    Evaluator.plot_results(results_df, best_cm)\n",
    "\n",
    "    return {\n",
    "        \"results_df\": results_df,\n",
    "        \"best_config\": best_config,\n",
    "        \"best_confusion_matrix\": best_cm\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Run the pipeline\n",
    "    config = Config()\n",
    "    results = train_and_evaluate(config)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
